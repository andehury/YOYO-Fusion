# YOYO-Fusion: Robust Merging in Residual Subspace

[![License](https://img.shields.io/badge/license-Apache%202.0-orange.svg)](LICENSE)

YOYO-Fusion is an efficient merging technique for large language models (LLMs). Its core advantage lies in realizing a "three-no" merging paradigm‚Äîno additional data required, no parameter tuning needed, and no dependence on pre-trained models.

This method can efficiently absorb the high-value knowledge and capabilities of multiple fine-tuned models while maintaining the model's strong robustness, providing a new approach for building high-performance models at low cost.

---

## Key Features

- **Consensus Center**: Determine the center (select a fine-tuned model) or estimate the center (standard median / geometric median).
- **Subspace Truncation**: Projects weight differences into a low-rank subspace using adaptive rank via principle rank to remove consensus noise.
- **Tukey Biweight**: Uses coordinate-wise and global Tukey biweight to suppress outliers in the subspace.
- **Matrix Boost**: Enhances residual components for linear/attention layers by equalizing singular values to the maximum.
- **Norm Preservation**: Always restores output tensor norm to the average L2 norm of input tensors.
- **Sign Alignment**: Optional coordinate-wise sign flipping to align directions with a reference model.
- **Z-Star Initialization Control**: Choose between median-based or zero-initialized robust center in subspace (`use_z_median`).
- **Full Compatibility**: Supports both single-file (`model.safetensors`) and sharded (`model.safetensors.index.json`) Hugging Face‚Äìstyle models.
- **Memory Efficient**: Processes one tensor at a time; no need to load all models fully into CPU memory.

---

## Quick Start

### Prerequisites

- Python >= 3.9
- PyTorch >= 2.0
- `safetensors`, `numpy`, `tqdm`

Install dependencies:
```bash
pip install torch safetensors numpy tqdm
```

### Basic Usage

```python
from yoyo_fusion import run_merge

run_merge(
    model_paths=[
        "path/to/model_A",
        "path/to/model_B",
        "path/to/model_C"
    ],
    output_dir="path/to/merged_model",
    anchor_index=0,                # 0: robust center; n‚â•1: use n-th model as anchor
    config_dir=1,                  # use config from the n-th model
    use_geometric_median=True,     # only used if anchor_index=0
    use_matrix_boost=False,        # apply Matrix Boost for linear/attention layers
    sign_reference_mode=0,         # 0: no alignment; n‚â•1: align signs to n-th model
    use_z_median=True,             # True: init z* with median; False: init with zeros
)
```

---

## Algorithm Steps

### Step 0: Inputs

A set of tensors:
```
ùíØ = {t‚ÇÅ, t‚ÇÇ, ..., t‚Çñ}
```
where K ‚â• 2 and each t·µ¢ ‚àà ‚Ñù·¥∞

**Parameters:**
- `anchor_index` ‚àà {0, 1, ..., K}
  - If 0: no anchor; use a robust center (median or geometric median)
  - If n ‚â• 1: use model n as anchor (i.e., t‚Çô)
- `use_geometric_median` ‚àà {True, False} (only effective when `anchor_index == 0`)
- `use_z_median` ‚àà {True, False}: controls initialization of `z*` in subspace fusion
- `use_matrix_boost` ‚àà {True, False}: applies singular-value equalization for 2D layers
- `sign_reference_mode` ‚àà {0, 1, ..., K}: enables coordinate-wise sign alignment to a reference model

### Step 1: Sign Alignment (Optional)

If `sign_reference_mode = r ‚â• 1`:
- For each element j, flip sign of t·µ¢‚±º if sign(t·µ¢‚±º) ‚â† sign(t·µ£‚±º) and t·µ£‚±º ‚â† 0.

Output aligned tensors: {tÃÉ‚ÇÅ, ..., tÃÉ‚Çñ}

### Step 2: Normalize Input Tensors

Compute RMS normalization for each tensor:
```
r·µ¢ = RMS(tÃÉ·µ¢) = ‚àö[(1/D) ‚àë‚±º‚Çå‚ÇÅ·¥∞ tÃÉ·µ¢‚±º¬≤ + Œµ], Œµ = 10‚Åª‚Å∏
```
```
u·µ¢ = tÃÉ·µ¢ / (r·µ¢ + Œµ)
```

Form normalized matrix:
```
U = [u‚ÇÅ, u‚ÇÇ, ..., u‚Çñ]·µÄ ‚àà ‚Ñù·¥∑√ó·¥∞
```

### Step 3: Determine Center Point m ‚àà ‚Ñù·¥∞

**Case A: anchor_index = n ‚â• 1**
```
m = u‚Çô
```

**Case B: anchor_index = 0**
- If `use_geometric_median = True`:  
  m = geometric median of {u‚ÇÅ, ..., u‚Çñ} via Weiszfeld-style iteration.
- Else:  
  m‚±º = median(u‚ÇÅ‚±º, ..., u‚Çñ‚±º), ‚àÄ j

### Step 4: Compute Residual Matrix

```
R = U - 1‚Çñ m·µÄ ‚àà ‚Ñù·¥∑√ó·¥∞
```

If ||R||_F < 10‚Åª‚Å∑, set y' = m and skip to Step 7.

### Step 5: SVD and Subspace Projection

Perform SVD on R·µÄ (in float64):
```
R·µÄ = U Œ£ V·µÄ
```

Compute total energy E = ‚àë œÉ·µ¢¬≤.  
Estimate effective rank via principle rank:
```
PR = (‚àë œÉ·µ¢¬≤)¬≤ / (‚àë œÉ·µ¢‚Å¥ + 10‚Åª¬π‚Å∂)
r_target = max(1, min(round(PR), K, rank(R)))
```

Compute energy-based scale factor:
```
E_retained = ‚àë_{i=1}^{r_target} œÉ·µ¢¬≤
Œ±_scale = min(‚àö(E / (E_retained + 10‚Åª¬π‚Å∂)), 10.0)
```

Project into subspace:
```
U_m = U[:, :r_target] ‚àà ‚Ñù·¥∞√ó ≥_target
Z = R U_m ‚àà ‚Ñù·¥∑√ó ≥_target
```

### Step 6: Robust Weighted Fusion in Subspace (Tukey Biweight)

- Initialize `z*`:
  ```
  - If use_z_median = True: z* = median(Z, dim=0)
  - If use_z_median = False: z* = 0 ‚àà ‚Ñù ≥_target
  ```
- Compute residual:
  ```
  Œî = Z ‚àí z*
  ```
- Per-dimension scale:
  ```
  s‚±º = 1.4826 ¬∑ median(|Œî‚ÇÅ‚±º|, ..., |Œî‚Çñ‚±º|)
  ```
- Global scale:
  ```
  s_global = 1.4826 ¬∑ median(||Œî‚ÇÅ||‚ÇÇ, ..., ||Œî‚Çñ||‚ÇÇ)
  ```
- Tukey weights (c = 4.685):
  ```
  w·µ¢‚±º^coord = [max(0, 1 ‚àí (|Œî·µ¢‚±º|/(c s‚±º))¬≤)]¬≤
  w·µ¢^global = [max(0, 1 ‚àí (||Œî·µ¢||‚ÇÇ/(c s_global))¬≤)]¬≤
  W·µ¢‚±º = w·µ¢‚±º^coord ¬∑ w·µ¢^global
  z* = (‚àë W·µ¢‚±º Z·µ¢‚±º) / (‚àë W·µ¢‚±º + Œµ)
  ```

Reconstruct residual:
```
r* = Œ±_scale ¬∑ U_m z*
```

### Step 7: Optional Matrix Boost

If `use_matrix_boost = True`, and tensor is 2D and not embedding/lm_head:
- Reshape r* ‚Üí R* ‚àà ‚Ñù^{m√ón}
- Compute SVD: R* = U_R Œ£_R V_R·µÄ
- If Œ£_R non-empty, set all singular values to œÉ_max = Œ£_R[0]
- Reconstruct: R_boost = U_R diag(œÉ_max, ..., œÉ_max) V_R·µÄ
- Update r* = vec(R_boost)

Final preliminary tensor:
```
y' = m + r*
```

### Step 8: Restore RMS Scale

```
rÃÑ = (1/K) ‚àë r·µ¢
y‚ÇÅ = y' ¬∑ rÃÑ
```

### Step 9: Norm Restoration (Fixed to Average)

Original L2 norms: n·µ¢ = ||tÃÉ·µ¢||‚ÇÇ  
Target norm: n_target = (1/K) ‚àë n·µ¢

Final scaling:
```
Œ± = n_target / (||y‚ÇÅ||‚ÇÇ + Œµ)
y = Œ± ¬∑ y‚ÇÅ
```

### Step 10: Output

**Merged Tensor = y ‚àà ‚Ñù·¥∞**, reshaped to original dimensions.

---

## Recommended Use Cases

| Scenario | Recommended Settings |
|--------|----------------------|
| Balanced fusion of multiple models | `anchor_index=0`, `use_geometric_median=True`, `use_z_median=True` |
| Preserve base model behavior | `anchor_index=1`, `sign_reference_mode=1`, `use_z_median=False` |
| Maximize robustness with fast convergence | `use_z_median=True`, `use_geometric_median=True` |
| Test ablation of median prior | `use_z_median=False`|

---

## Directory Structure

Your model directories should follow Hugging Face conventions:

```
model_A/
‚îú‚îÄ‚îÄ model.safetensors          # (single-file) OR
‚îú‚îÄ‚îÄ model-00001-of-00002.safetensors
‚îú‚îÄ‚îÄ model-00002-of-00002.safetensors
‚îî‚îÄ‚îÄ model.safetensors.index.json

model_B/
‚îú‚îÄ‚îÄ ...
```

The script auto-detects whether models are sharded or single-file and handles both.

---

## Parameters Explained

| Parameter | Type | Description |
|---|---|---|
| `model_paths` | List[str] | Paths to input model directories (‚â•2) |
| `output_dir` | str | Output directory for merged model |
| `anchor_index` | int | 0: robust center; n‚â•1: use n-th model as anchor (1-based) |
| `config_dir` | int | Which model‚Äôs config/index files to copy (1-based) |
| `use_geometric_median` | bool | Use geometric median instead of coordinate-wise median (only if `anchor_index=0`) |
| `use_matrix_boost` | bool | Apply Matrix Boost to 2D linear/attention layers |
| `sign_reference_mode` | int | 0: no alignment; n‚â•1: align signs to n-th model |
| `use_z_median` | bool | True: initialize `z*` with median in subspace; False: use zero vector |

---

## License

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.

---

**Note**: This tool merges weights only. It does not merge tokenizers, configs, or generation settings‚Äîthose are copied from the config_dir model. Always verify compatibility of input models (same architecture, vocab size, etc.).
