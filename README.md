# YOYO-Fusion: Plug-and-Play Merging of Arbitrary Fine-Tunes with Shared Architecture

[![License](https://img.shields.io/badge/license-Apache%202.0-orange.svg)](LICENSE)

YOYO-Fusion is an efficient merging technique for large language models (LLMs). Its core advantage lies in realizing a "three-no" merging paradigm‚Äîno additional data required, no parameter tuning needed, and no dependence on pre-trained models.

This method can efficiently absorb the high-value knowledge and capabilities of multiple fine-tuned models while maintaining the model's strong robustness, providing a new approach for building high-performance models at low cost.

---

## Key Features

- Consensus Center: Determine the center (select a fine-tuned model) or estimate the center (lower median / geometric median)
- Subspace Truncation: Projects weight differences into a low-rank subspace (rank ‚â§ K‚àí1 for K models) to remove consensus noise.
- Outlier Suppression: Applies Tukey‚Äôs biweight weighting in the subspace to downweight anomalous models per dimension.
- Norm Preservation: Automatically rescales output to match the average norm statistics of input models.
- Full Compatibility: Supports both single-file (`model.safetensors`) and sharded (`model.safetensors.index.json`) Hugging Face‚Äìstyle models.
- Memory Efficient: Processes one tensor at a time; no need to load all models fully into GPU memory.

---

## Quick Start

### Prerequisites

- Python >= 3.9
- PyTorch >= 2.0
- `safetensors`, `numpy`, `tqdm`

Install dependencies:
```bash
pip install torch safetensors numpy tqdm
```

### Basic Usage

```python
from yoyo_fusion import run_merge

run_merge(
    model_paths=[
        "path/to/model_A",
        "path/to/model_B",
        "path/to/model_C"
    ],
    output_dir="path/to/merged_model",
    anchor_index=0,  # n=0: no anchor n>=1: use n-th model as anchor
    config_dir=1,    # m>=1 use m-th as config
    use_k_minus_one_truncation=True,  # True: truncation + energy scaling False: full SVD
    use_geometric_median=True,        # True: use geometric median False: use standard median
)
```

---

## Algorithm Steps


### Step 0: Inputs

A set of tensors:
```
ùíØ = {t‚ÇÅ, t‚ÇÇ, ..., t‚Çñ}
```
where K ‚â• 2 and each t·µ¢ ‚àà ‚Ñù·¥∞

**Parameters:**
- `anchor_index` ‚àà {0, 1, ..., K}
  - If 0: no anchor; use a robust center (median or geometric median)
  - If n ‚â• 1: use model n as anchor (i.e., t‚Çô)
- `use_geometric_median` ‚àà {True, False} (only effective when anchor_index == 0)
- `use_k_minus_one_truncation` ‚àà {True, False}

### Step 1: Normalize Input Tensors

Compute RMS normalization for each tensor:
```
r·µ¢ = RMS(t·µ¢) = ‚àö[(1/D) ‚àë‚±º‚Çå‚ÇÅ·¥∞ t·µ¢‚±º¬≤ + Œµ], where Œµ = 10‚Åª‚Å∏
```
```
u·µ¢ = t·µ¢ / (r·µ¢ + Œµ)
```

Obtain normalized tensor matrix:
```
U = [u‚ÇÅ, u‚ÇÇ, ..., u‚Çñ]·µÄ ‚àà ‚Ñù·¥∑√ó·¥∞
```

### Step 2: Determine Center Point m ‚àà ‚Ñù·¥∞

**Case A: anchor_index = n (n ‚â• 1) (anchor mode)**
```
m = u‚Çô
```

Note: anchor_index = 1 corresponds to the first model (model_dirs[0]) due to 1-based indexing in the parameter.

**Case B: anchor_index = 0 (no anchor)**

**Subcase B1: use_geometric_median = True**
Compute the geometric median via the Weiszfeld algorithm:
```
m = argmin·µß ‚àë·µ¢‚Çå‚ÇÅ·¥∑ ||u·µ¢ - y||‚ÇÇ
```

Initialized with the coordinate-wise median and iterated to convergence.

**Subcase B2: use_geometric_median = False**
Use coordinate-wise median:
```
m‚±º = median(u‚ÇÅ‚±º, u‚ÇÇ‚±º, ..., u‚Çñ‚±º), ‚àÄ j = 1,...,D
```

### Step 3: Compute Residual Matrix
```
R = U - 1‚Çñm·µÄ ‚àà ‚Ñù·¥∑√ó·¥∞
```

where 1‚Çñ is a column vector of ones.

If ||R||_F < 10‚Åª‚Å∑ (models are nearly identical), set:
```
y' = m
```
and skip to Step 6.

### Step 4: SVD Decomposition and Subspace Truncation

Perform SVD on R·µÄ ‚àà ‚Ñù·¥∞√ó·¥∑ (in float64 for numerical stability):
```
R·µÄ = UŒ£V·µÄ
```

where U ‚àà ‚Ñù·¥∞√ó ≥, Œ£ ‚àà ‚Ñù ≥√ó ≥, and r = min(K, D)

Determine target rank r_target and scaling flag:
- If use_k_minus_one_truncation = True:
  ```
  r_target = min(K - 1, r)
  ```
  and energy scaling is enabled
- If use_k_minus_one_truncation = False:
  ```
  r_target = min(K, r)
  ```
  and no scaling is applied
- If r_target ‚â§ 0, return y' = m

If energy scaling is enabled (use_k_minus_one_truncation = True):
```
p = [‚àë·µ¢‚Çå‚ÇÅ ≥_target œÉ·µ¢¬≤] / [‚àë·µ¢‚Çå‚ÇÅ ≥ œÉ·µ¢¬≤ + Œµ]
```
```
Œ±_scale = min(1/(p + Œµ), 10.0)
```

Extract top r_target left singular vectors:
```
U_m = U[:, :r_target] ‚àà ‚Ñù·¥∞√ó ≥_target
```

Project residuals onto subspace:
```
Z = RU_m ‚àà ‚Ñù·¥∑√ó ≥_target
```

### Step 5: Robust Weighted Averaging (M-estimator with Tukey Biweight)

For each dimension j = 1, ..., r_target:

Compute MAD-based scale estimate:
```
s‚±º = 1.4826 ¬∑ median(|Z‚ÇÅ‚±º|, ..., |Z‚Çñ‚±º|)
```

Ensure numerical stability:
```
s‚±º = max(s‚±º, 10‚Åª¬π¬≤)
```

Compute global row norms:
```
||z·µ¢||‚ÇÇ = ‚àö[‚àë‚±º‚Çå‚ÇÅ ≥_target Z·µ¢‚±º¬≤], i = 1,...,K
```
```
s_global = 1.4826 ¬∑ median(||z‚ÇÅ||‚ÇÇ, ..., ||z‚Çñ||‚ÇÇ)
```

Tukey biweight weights (with tuning constant c = 4.685):

Coordinate-wise weights:
```
w·µ¢‚±º^coord = 
{ [1 - (|Z·µ¢‚±º|/(c¬∑s‚±º))¬≤]¬≤ if |Z·µ¢‚±º| < c¬∑s‚±º
{ 0 otherwise
```

Global weights:
```
w·µ¢^global = 
{ [1 - (||z·µ¢||‚ÇÇ/(c¬∑s_global))¬≤]¬≤ if ||z·µ¢||‚ÇÇ < c¬∑s_global
{ 0 otherwise
```

Combined weights:
```
W·µ¢‚±º = w·µ¢‚±º^coord ¬∑ w·µ¢^global
```

Compute weighted average per dimension:
```
z‚±º* = [‚àë·µ¢‚Çå‚ÇÅ·¥∑ W·µ¢‚±ºZ·µ¢‚±º] / [‚àë·µ¢‚Çå‚ÇÅ·¥∑ W·µ¢‚±º + Œµ]
```

yielding z* ‚àà ‚Ñù ≥_target

Map back to original space:
```
r* = Œ±_scale ¬∑ U_mz*
```

Preliminary merged tensor:
```
y' = m + r*
```

### Step 6: Restore Original Scale and Normalize

Mean RMS of original tensors:
```
rÃÑ = (1/K) ‚àë·µ¢‚Çå‚ÇÅ·¥∑ r·µ¢
```
```
y‚ÇÅ = y' ¬∑ rÃÑ
```

Mean L2 norm of original tensors:
```
nÃÑ = (1/K) ‚àë·µ¢‚Çå‚ÇÅ·¥∑ ||t·µ¢||‚ÇÇ
```

Norm of current merged tensor:
```
n_y = ||y‚ÇÅ||‚ÇÇ
```

Final scaling to match average norm:
```
Œ± = nÃÑ / (n_y + Œµ), y = Œ± ¬∑ y‚ÇÅ
```

### Step 7: Output

**Merged Tensor = y ‚àà ‚Ñù·¥∞**

Reshape to original tensor shape.
---

## Recommended Use Cases

| Scenario | Recommended Settings |
|--------|----------------------|
| Absorb multiple models in a balanced manner | `anchor_index=0`,`use_geometric_median=True/False`,`use_k_minus_one_truncation=True` |
| Preserve behavior of a specific model | `anchor_index=1`,`use_k_minus_one_truncation=True` |

---

## Directory Structure

Your model directories should follow Hugging Face conventions:

```
model_A/
‚îú‚îÄ‚îÄ model.safetensors          # (single-file) OR
‚îú‚îÄ‚îÄ model-00001-of-00002.safetensors
‚îú‚îÄ‚îÄ model-00002-of-00002.safetensors
‚îî‚îÄ‚îÄ model.safetensors.index.json

model_B/
‚îú‚îÄ‚îÄ ...
```

The script auto-detects whether models are sharded or single-file and handles both.

---

## Parameters Explained

|Parameter|Type|Description|
|---|---|---|
|model_paths|List[str]|Paths to input model directories (>=2)|
|output_dir|str|Output directory for merged model|
|anchor_index|int|0: no anchor (robust center); n>=1: use n-th model as anchor (1-based)|
|config_dir|int|Which model‚Äôs config/index files to copy|
|use_k_minus_one_truncation|bool|True: truncation + energy scaling False: full SVD (no truncation)|
|use_geometric_median|bool|True: use geometric median False: use lower median (only if `anchor_index=0`) |

---

## License

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
---
Note: This tool merges weights only. It does not merge tokenizers, configs, or generation settings‚Äîthose are copied from the config_dir model. Always verify compatibility of input models (same architecture, vocab size, etc.).
