# YOYO-Fusion: Robust Merging in Residual Subspace

[![License](https://img.shields.io/badge/license-Apache%202.0-orange.svg)](LICENSE)

YOYO-Fusion is an efficient merging technique for large language models (LLMs). Its core advantage lies in realizing a "three-no" merging paradigm‚Äîno additional data required, no parameter tuning needed, and no dependence on pre-trained models.

This method can efficiently absorb the high-value knowledge and capabilities of multiple fine-tuned models while maintaining the model's strong robustness, providing a new approach for building high-performance models at low cost.

---

## Key Features

- **Consensus Center**: Determine the center (select a fine-tuned model) or estimate the center (standard median / geometric median).
- **Subspace Truncation**: Projects weight differences into a low-rank subspace using adaptive rank via principle rank to remove consensus noise.
- **IRLS Option**: Supports both IRLS-based Welsch weighting and Tukey biweight for outlier suppression in the subspace.
- **Matrix Boost**: Enhances residual components for linear/attention layers by equalizing singular values to the maximum.
- **Norm Preservation**: Restores output tensor norm to match either the average or a specific input model‚Äôs norm.
- **Sign Alignment**: Optional coordinate-wise sign flipping to align directions with a reference model.
- **Full Compatibility**: Supports both single-file (`model.safetensors`) and sharded (`model.safetensors.index.json`) Hugging Face‚Äìstyle models.
- **Memory Efficient**: Processes one tensor at a time; no need to load all models fully into CPU memory.

---

## Quick Start

### Prerequisites

- Python >= 3.9
- PyTorch >= 2.0
- `safetensors`, `numpy`, `tqdm`

Install dependencies:
```bash
pip install torch safetensors numpy tqdm
```

### Basic Usage

```python
from yoyo_fusion import run_merge

run_merge(
    model_paths=[
        "path/to/model_A",
        "path/to/model_B",
        "path/to/model_C"
    ],
    output_dir="path/to/merged_model",
    anchor_index=0,                # 0: robust center; n‚â•1: use n-th model as anchor
    config_dir=1,                  # use config from the n-th model (1-based)
    use_geometric_median=True,     # only used if anchor_index=0
    use_matrix_boost=False,        # apply Matrix Boost for linear/attention layers
    sign_reference_mode=0,         # 0: no alignment; n‚â•1: align signs to n-th model
    norm_restore_mode=0,           # 0: average norm; n‚â•1: use n-th model‚Äôs norm
    use_irls=True,                 # True: Welsch IRLS; False: Tukey biweight
)
```

---

## Algorithm Steps

### Step 0: Inputs

A set of tensors:
```
ùíØ = {t‚ÇÅ, t‚ÇÇ, ..., t‚Çñ}
```
where K ‚â• 2 and each t·µ¢ ‚àà ‚Ñù·¥∞

**Parameters:**
- `anchor_index` ‚àà {0, 1, ..., K}
  - If 0: no anchor; use a robust center (median or geometric median)
  - If n ‚â• 1: use model n as anchor (i.e., t‚Çô)
- `use_geometric_median` ‚àà {True, False} (only effective when `anchor_index == 0`)
- `use_irls` ‚àà {True, False}: selects between Welsch IRLS (iterative) or Tukey biweight (non-iterative) robust fusion
- `use_matrix_boost` ‚àà {True, False}: applies singular-value equalization for 2D layers
- `sign_reference_mode` ‚àà {0, 1, ..., K}: enables coordinate-wise sign alignment to a reference model
- `norm_restore_mode` ‚àà {0, 1, ..., K}: selects norm target for final scaling

### Step 1: Sign Alignment (Optional)

If `sign_reference_mode = r ‚â• 1`:
- For each element j, flip sign of t·µ¢‚±º if sign(t·µ¢‚±º) ‚â† sign(t·µ£‚±º) and t·µ£‚±º ‚â† 0.

Output aligned tensors: {tÃÉ‚ÇÅ, ..., tÃÉ‚Çñ}

### Step 2: Normalize Input Tensors

Compute RMS normalization for each tensor:
```
r·µ¢ = RMS(tÃÉ·µ¢) = ‚àö[(1/D) ‚àë‚±º‚Çå‚ÇÅ·¥∞ tÃÉ·µ¢‚±º¬≤ + Œµ], Œµ = 10‚Åª‚Å∏
```
```
u·µ¢ = tÃÉ·µ¢ / (r·µ¢ + Œµ)
```

Form normalized matrix:
```
U = [u‚ÇÅ, u‚ÇÇ, ..., u‚Çñ]·µÄ ‚àà ‚Ñù·¥∑√ó·¥∞
```

### Step 3: Determine Center Point m ‚àà ‚Ñù·¥∞

**Case A: anchor_index = n ‚â• 1**
```
m = u‚Çô
```

**Case B: anchor_index = 0**
- If `use_geometric_median = True`:  
  m = geometric median of {u‚ÇÅ, ..., u‚Çñ} via Weiszfeld-style iteration.
- Else:  
  m‚±º = median(u‚ÇÅ‚±º, ..., u‚Çñ‚±º), ‚àÄ j

### Step 4: Compute Residual Matrix

```
R = U - 1‚Çñ m·µÄ ‚àà ‚Ñù·¥∑√ó·¥∞
```

If ||R||_F < 10‚Åª‚Å∑, set y' = m and skip to Step 7.

### Step 5: SVD and Subspace Projection

Perform SVD on R·µÄ (in float64):
```
R·µÄ = U Œ£ V·µÄ
```

Compute total energy E = ‚àë œÉ·µ¢¬≤.  
Estimate effective rank via principle rank:
```
PR = (‚àë œÉ·µ¢¬≤)¬≤ / (‚àë œÉ·µ¢‚Å¥ + 10‚Åª¬π‚Å∂)
r_target = max(1, min(round(PR), K, rank(R)))
```

Compute energy-based scale factor:
```
E_retained = ‚àë_{i=1}^{r_target} œÉ·µ¢¬≤
Œ±_scale = min(‚àö(E / (E_retained + 10‚Åª¬π‚Å∂)), 10.0)
```

Project into subspace:
```
U_m = U[:, :r_target] ‚àà ‚Ñù·¥∞√ó ≥_target
Z = R U_m ‚àà ‚Ñù·¥∑√ó ≥_target
```

### Step 6: Robust Weighted Fusion in Subspace

#### If `use_irls = True` (Welsch IRLS):
- Initialize z* = median(Z, dim=0)
- Iterate up to `irls_max_iter`:
  - Compute residual Œî = Z ‚àí z*
  - Per-dimension scale: s‚±º = 1.4826 ¬∑ median(|Œî‚ÇÅ‚±º|, ..., |Œî‚Çñ‚±º|)
  - Global scale: s_global = 1.4826 ¬∑ median(||Œî‚ÇÅ||‚ÇÇ, ..., ||Œî‚Çñ||‚ÇÇ)
  - Welsch weights (c = 2.985):
    ```
    w·µ¢‚±º = exp(‚àí( |Œî·µ¢‚±º| / (c s‚±º) )¬≤ ) ¬∑ exp(‚àí( ||Œî·µ¢||‚ÇÇ / (c s_global) )¬≤ )
    ```
  - Update: z* = (‚àë w·µ¢‚±º Z·µ¢‚±º) / (‚àë w·µ¢‚±º + Œµ)
  - Stop if ||z*‚Çô‚Çëùìå ‚àí z*|| < tol

#### If `use_irls = False` (Tukey Biweight):
- Single-step computation with c = 4.685:
  ```
  w·µ¢‚±º^coord = [max(0, 1 ‚àí (|Œî·µ¢‚±º|/(c s‚±º))¬≤)]¬≤
  w·µ¢^global = [max(0, 1 ‚àí (||Œî·µ¢||‚ÇÇ/(c s_global))¬≤)]¬≤
  W·µ¢‚±º = w·µ¢‚±º^coord ¬∑ w·µ¢^global
  z* = (‚àë W·µ¢‚±º Z·µ¢‚±º) / (‚àë W·µ¢‚±º + Œµ)
  ```

Reconstruct residual:
```
r* = Œ±_scale ¬∑ U_m z*
```

### Step 7: Optional Matrix Boost

If `use_matrix_boost = True`, and tensor is 2D and not embedding/lm_head:
- Reshape r* ‚Üí R* ‚àà ‚Ñù^{m√ón}
- Compute SVD: R* = U_R Œ£_R V_R·µÄ
- If Œ£_R non-empty, set all singular values to œÉ_max = Œ£_R[0]
- Reconstruct: R_boost = U_R diag(œÉ_max, ..., œÉ_max) V_R·µÄ
- Update r* = vec(R_boost)

Final preliminary tensor:
```
y' = m + r*
```

### Step 8: Restore RMS Scale

```
rÃÑ = (1/K) ‚àë r·µ¢
y‚ÇÅ = y' ¬∑ rÃÑ
```

### Step 9: Norm Restoration

Original L2 norms: n·µ¢ = ||tÃÉ·µ¢||‚ÇÇ

- If `norm_restore_mode = 0`: n_target = (1/K) ‚àë n·µ¢
- If `norm_restore_mode = m ‚â• 1`: n_target = n‚Çò‚Çã‚ÇÅ

Final scaling:
```
Œ± = n_target / (||y‚ÇÅ||‚ÇÇ + Œµ)
y = Œ± ¬∑ y‚ÇÅ
```

### Step 10: Output

**Merged Tensor = y ‚àà ‚Ñù·¥∞**, reshaped to original dimensions.

---

## Recommended Use Cases

| Scenario | Recommended Settings |
|--------|----------------------|
| Balanced fusion of multiple models | `anchor_index=0`, `use_geometric_median=True`, `use_irls=True` |
| Preserve base model behavior | `anchor_index=1`, `sign_reference_mode=1`, `norm_restore_mode=1` |
| Maximize robustness against outliers | `use_irls=True`, `use_geometric_median=True` |
| Fast fusion with strong noise suppression | `use_irls=False`, `use_matrix_boost=False` |

---

## Directory Structure

Your model directories should follow Hugging Face conventions:

```
model_A/
‚îú‚îÄ‚îÄ model.safetensors          # (single-file) OR
‚îú‚îÄ‚îÄ model-00001-of-00002.safetensors
‚îú‚îÄ‚îÄ model-00002-of-00002.safetensors
‚îî‚îÄ‚îÄ model.safetensors.index.json

model_B/
‚îú‚îÄ‚îÄ ...
```

The script auto-detects whether models are sharded or single-file and handles both.

---

## Parameters Explained

| Parameter | Type | Description |
|---|---|---|
| `model_paths` | List[str] | Paths to input model directories (‚â•2) |
| `output_dir` | str | Output directory for merged model |
| `anchor_index` | int | 0: robust center; n‚â•1: use n-th model as anchor (1-based) |
| `config_dir` | int | Which model‚Äôs config/index files to copy (1-based) |
| `use_geometric_median` | bool | Use geometric median instead of coordinate-wise median (only if `anchor_index=0`) |
| `use_matrix_boost` | bool | Apply Matrix Boost to 2D linear/attention layers |
| `sign_reference_mode` | int | 0: no alignment; n‚â•1: align signs to n-th model |
| `norm_restore_mode` | int | 0: match average L2 norm; n‚â•1: match n-th model‚Äôs norm |
| `use_irls` | bool | True: use Welsch IRLS (iterative); False: use Tukey biweight (single-step) |

---

## License

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.

---

**Note**: This tool merges weights only. It does not merge tokenizers, configs, or generation settings‚Äîthose are copied from the config_dir model. Always verify compatibility of input models (same architecture, vocab size, etc.).
